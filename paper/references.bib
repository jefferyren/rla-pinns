@book{guermond2021finite,
  title =        {{Finite Elements I: Approximation and Interpolation}},
  author =       {Guermond, Jean-Luc and Ern, Alexandre},
  year =         2021,
  publisher =    {Springer}
}

@book{rudin1970real,
  title =        {{Real and Complex Analysis P. 2}},
  author =       {Rudin, Walter},
  year =         1970,
  publisher =    {McGraw-Hill}
}

@book{rudin1976principles,
  title =        {{Principles of mathematical analysis}},
  author =       {Rudin, Walter and others},
  volume =       3,
  year =         1976,
  publisher =    {McGraw-hill New York}
}

@book{werner2006funktionalanalysis,
  title =        {Funktionalanalysis},
  author =       {Werner, Dirk},
  year =         2006,
  publisher =    {Springer-Verlag}
}

@book{girault1979finite,
  title =        {{Finite element approximation of the Navier-Stokes equations}},
  author =       {Girault, Vivette and Raviart, Pierre-Arnaud},
  volume =       749,
  year =         1979,
  publisher =    {Springer Berlin}
}

@book{brezis2011functional,
  title =        {{Functional analysis, Sobolev spaces and partial differential
                  equations}},
  author =       {Brezis, Haim and Br{\'e}zis, Haim},
  volume =       2,
  number =       3,
  year =         2011,
  publisher =    {Springer}
}

@book{di2011mathematical,
  title =        {{Mathematical aspects of discontinuous Galerkin methods}},
  author =       {Di Pietro, Daniele Antonio and Ern, Alexandre},
  volume =       69,
  year =         2011,
  publisher =    {Springer Science \& Business Media}
}

@inproceedings{dangel2020modular,
  title =        {{Modular Block-diagonal Curvature Approximations for
                  Feedforward Architectures}},
  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2020,
}

@inproceedings{martens2015optimizing,
  title =        {{Optimizing Neural Networks with {K}ronecker-factored
                  Approximate Curvature}},
  author =       {Martens, James and Grosse, Roger},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@article{skorski2019chain,
  title =        {{Chain rules for hessian and higher derivatives made easy by
                  tensor calculus}},
  author =       {Skorski, Maciej},
  journal =      {arXiv preprint arXiv:1911.13292},
  year =         2019
}

@inproceedings{martens2018kroneckerfactored,
  title =        {{Kronecker-factored Curvature Approximations for Recurrent
                  Neural Networks}},
  author =       {James Martens and Jimmy Ba and Matt Johnson},
  booktitle =    {International Conference on Learning Representations},
  year =         2018,
  url =          {https://openreview.net/forum?id=HyMTkQZAb},
}

@inproceedings{eschenhagen2023kroneckerfactored,
  title =        {{Kronecker-Factored Approximate Curvature for Modern Neural
                  Network Architectures}},
  author =       {Runa Eschenhagen and Alexander Immer and Richard E. Turner and
                  Frank Schneider and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2023,
}

@article{amari1998natural,
  title =        {Natural gradient works efficiently in learning},
  author =       {Amari, Shun-Ichi},
  journal =      {Neural computation},
  volume =       10,
  number =       2,
  pages =        {251--276},
  year =         1998,
  publisher =    {MIT Press}
}

@inproceedings{arora2018understanding,
  title =        {{Understanding Deep Neural Networks with Rectified Linear
                  Units}},
  author =       {Raman Arora and Amitabh Basu and Poorya Mianjy and Anirbit
                  Mukherjee},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@inproceedings{grosse2016kroneckerfactored,
  author =       {Grosse, Roger and Martens, James},
  title =        {{A Kronecker-Factored Approximate {F}isher Matrix for
                  Convolution Layers}},
  year =         2016,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@misc{martens2020new,
  title =        {New insights and perspectives on the natural gradient method},
  author =       {James Martens},
  year =         2020,
}

@inproceedings{muller2023achieving,
  title =        {{Achieving high accuracy with PINNs via energy natural
                  gradient descent}},
  author =       {M{\"u}ller, Johannes and Zeinhofer, Marius},
  booktitle =    {International Conference on Machine Learning},
  pages =        {25471--25485},
  year =         2023,
  organization = {PMLR}
}

@article{dissanayake1994neural,
  title =        {Neural-network-based approximations for solving partial
                  differential equations},
  author =       {Dissanayake, MWMG and Phan-Thien, Nhan},
  journal =      {communications in Numerical Methods in Engineering},
  volume =       10,
  number =       3,
  pages =        {195--201},
  year =         1994,
  publisher =    {Wiley Online Library}
}

@article{hu2024score,
  title =        {Score-Based Physics-Informed Neural Networks for
                  High-Dimensional Fokker-Planck Equations},
  author =       {Hu, Zheyuan and Zhang, Zhongqiang and Karniadakis, George Em
                  and Kawaguchi, Kenji},
  journal =      {arXiv preprint arXiv:2402.07465},
  year =         2024
}

@article{wang20222,
  title =        {Is $L^{2}$ Physics Informed Loss Always Suitable for Training
                  Physics Informed Neural Network?},
  author =       {Wang, Chuwei and Li, Shanda and He, Di and Wang, Liwei},
  journal =      {Advances in Neural Information Processing Systems},
  volume =       35,
  pages =        {8278--8290},
  year =         2022
}

@article{lagaris1998artificial,
  title =        {Artificial neural networks for solving ordinary and partial
                  differential equations},
  author =       {Lagaris, Isaac E and Likas, Aristidis and Fotiadis, Dimitrios
                  I},
  journal =      {IEEE transactions on neural networks},
  volume =       9,
  number =       5,
  pages =        {987--1000},
  year =         1998,
  publisher =    {IEEE}
}

@article{raissi2019physics,
  title =        {Physics-informed neural networks: A deep learning framework
                  for solving forward and inverse problems involving nonlinear
                  partial differential equations},
  author =       {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George
                  E},
  journal =      {Journal of Computational physics},
  volume =       378,
  pages =        {686--707},
  year =         2019,
  publisher =    {Elsevier}
}

@article{sirignano2018dgm,
  title =        {DGM: A deep learning algorithm for solving partial
                  differential equations},
  author =       {Sirignano, Justin and Spiliopoulos, Konstantinos},
  journal =      {Journal of computational physics},
  volume =       375,
  pages =        {1339--1364},
  year =         2018,
  publisher =    {Elsevier}
}

@article{zeng2022competitive,
  title =        {Competitive physics informed networks},
  author =       {Zeng, Qi and Kothari, Yash and Bryngelson, Spencer H and
                  Sch{\"a}fer, Florian},
  journal =      {arXiv preprint arXiv:2204.11144},
  year =         2022
}

@article{de2023operator,
  title =        {An operator preconditioning perspective on training in
                  physics-informed machine learning},
  author =       {De Ryck, Tim and Bonnet, Florent and Mishra, Siddhartha and de
                  B{\'e}zenac, Emmanuel},
  journal =      {arXiv preprint arXiv:2310.05801},
  year =         2023
}

@article{liu2024preconditioning,
  title =        {Preconditioning for Physics-Informed Neural Networks},
  author =       {Liu, Songming and Su, Chang and Yao, Jiachen and Hao, Zhongkai
                  and Su, Hang and Wu, Youjia and Zhu, Jun},
  journal =      {arXiv preprint arXiv:2402.00531},
  year =         2024
}

@article{markidis2021old,
  title =        {The old and the new: Can physics-informed deep-learning
                  replace traditional linear solvers?},
  author =       {Markidis, Stefano},
  journal =      {Frontiers in big Data},
  volume =       4,
  pages =        669097,
  year =         2021,
  publisher =    {Frontiers}
}

@article{lu2021deepxde,
  title =        {{DeepXDE}: A deep learning library for solving differential
                  equations},
  author =       {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis,
                  George Em},
  journal =      {SIAM Review},
  volume =       63,
  number =       1,
  pages =        {208--228},
  year =         2021,
  publisher =    {SIAM}
}

@article{nabian2021efficient,
  title =        {Efficient training of physics-informed neural networks via
                  importance sampling},
  author =       {Nabian, Mohammad Amin and Gladstone, Rini Jasmine and Meidani,
                  Hadi},
  journal =      {Computer-Aided Civil and Infrastructure Engineering},
  volume =       36,
  number =       8,
  pages =        {962--977},
  year =         2021,
  publisher =    {Wiley Online Library}
}

@article{daw2022rethinking,
  title =        {Rethinking the importance of sampling in physics-informed
                  neural networks},
  author =       {Daw, Arka and Bu, Jie and Wang, Sifan and Perdikaris, Paris
                  and Karpatne, Anuj},
  journal =      {arXiv preprint arXiv:2207.02338},
  year =         2022
}

@article{zapf2022investigating,
  title =        {{Investigating molecular transport in the human brain from MRI
                  with physics-informed neural networks}},
  author =       {Zapf, Bastian and Haubner, Johannes and Kuchta, Miroslav and
                  Ringstad, Geir and Eide, Per Kristian and Mardal, Kent-Andre},
  journal =      {Scientific Reports},
  volume =       12,
  number =       1,
  pages =        {1--12},
  year =         2022,
  publisher =    {Nature Publishing Group}
}

@article{wang2021understanding,
  title =        {Understanding and mitigating gradient flow pathologies in
                  physics-informed neural networks},
  author =       {Wang, Sifan and Teng, Yujun and Perdikaris, Paris},
  journal =      {SIAM Journal on Scientific Computing},
  volume =       43,
  number =       5,
  pages =        {A3055--A3081},
  year =         2021,
  publisher =    {SIAM}
}

@article{wang2022and,
  title =        {When and why {PINNs} fail to train: A neural tangent kernel
                  perspective},
  author =       {Wang, Sifan and Yu, Xinling and Perdikaris, Paris},
  journal =      {Journal of Computational Physics},
  volume =       449,
  pages =        110768,
  year =         2022,
  publisher =    {Elsevier}
}

@article{wu2023comprehensive,
  title =        {A comprehensive study of non-adaptive and residual-based
                  adaptive sampling for physics-informed neural networks},
  author =       {Wu, Chenxi and Zhu, Min and Tan, Qinyang and Kartha, Yadhu and
                  Lu, Lu},
  journal =      {Computer Methods in Applied Mechanics and Engineering},
  volume =       403,
  pages =        115671,
  year =         2023,
  publisher =    {Elsevier}
}

@article{van2022optimally,
  title =        {Optimally weighted loss functions for solving {PDE}s with
                  neural networks},
  author =       {van der Meer, Remco and Oosterlee, Cornelis W and Borovykh,
                  Anastasia},
  journal =      {Journal of Computational and Applied Mathematics},
  volume =       405,
  pages =        113887,
  year =         2022,
  publisher =    {Elsevier}
}

@article{wang2022respecting,
  title =        {Respecting causality is all you need for training
                  physics-informed neural networks},
  author =       {Wang, Sifan and Sankaran, Shyam and Perdikaris, Paris},
  journal =      {arXiv preprint arXiv:2203.07404},
  year =         2022
}

@article{li2023forward,
  title =        {{Forward Laplacian: A New Computational Framework for Neural
                  Network-based Variational Monte Carlo}},
  author =       {Li, Ruichen and Ye, Haotian and Jiang, Du and Wen, Xuelan and
                  Wang, Chuwei and Li, Zhe and Li, Xiang and He, Di and Chen, Ji
                  and Ren, Weiluo and others},
  year =         2023,
}

@inproceedings{bettencourt2019taylor,
  title =        {Taylor-mode automatic differentiation for higher-order
                  derivatives in {JAX}},
  author =       {Bettencourt, Jesse and Johnson, Matthew J and Duvenaud, David},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS);
                  Workhop on Program Transformations for ML},
  year =         2019
}

@book{griewank2008evaluating,
  title =        {Evaluating derivatives: principles and techniques of
                  algorithmic differentiation},
  author =       {Griewank, Andreas and Walther, Andrea},
  year =         2008,
  publisher =    {SIAM}
}

@article{griewank1996algorithm,
  title =        {{Algorithm 755: ADOL-C: A package for the automatic
                  differentiation of algorithms written in C/C++}},
  author =       {Griewank, Andreas and Juedes, David and Utke, Jean},
  journal =      {ACM Transactions on Mathematical Software (TOMS)},
  volume =       22,
  number =       2,
  pages =        {131--167},
  year =         1996,
  publisher =    {ACM New York, NY, USA}
}

@inproceedings{benzing2022gradient,
  title =        {{Gradient Descent on Neurons and its Link to Approximate
                  Second-order Optimization}},
  author =       {Benzing, Frederik},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2022,
}

@inproceedings{petersen2023isaac,
  title =        {{{ISAAC} Newton: Input-based Approximate Curvature for
                  Newton's Method}},
  author =       {Felix Petersen and Tobias Sutter and Christian Borgelt and
                  Dongsung Huh and Hilde Kuehne and Yuekai Sun and Oliver
                  Deussen},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2023,
}

@article{lin2023simplifying,
  title =        {{Simplifying Momentum-based Riemannian Submanifold
                  Optimization}},
  author =       {Lin, Wu and Duruisseaux, Valentin and Leok, Melvin and
                  Nielsen, Frank and Khan, Mohammad Emtiyaz and Schmidt, Mark},
  year =         2023
}

@article{lin2023structured,
  title =        {{Structured Inverse-Free Natural Gradient: Memory-Efficient \&
                  Numerically-Stable KFAC for Large Neural Nets}},
  author =       {Lin, Wu and Dangel, Felix and Eschenhagen, Runa and Neklyudov,
                  Kirill and Kristiadi, Agustinus and Turner, Richard E and
                  Makhzani, Alireza},
  year =         2023,
}

@inproceedings{dangel2020backpack,
  title =        {{{B}ack{PACK}: Packing more into Backprop}},
  author =       {Felix Dangel and Frederik Kunstner and Philipp Hennig},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2020,
}

@article{stokes2020quantum,
  title =        {Quantum natural gradient},
  author =       {Stokes, James and Izaac, Josh and Killoran, Nathan and Carleo,
                  Giuseppe},
  journal =      {Quantum},
  volume =       4,
  pages =        269,
  year =         2020,
  publisher =    {Verein zur F{\"o}rderung des Open Access Publizierens in den
                  Quantenwissenschaften}
}

@article{webber2022rayleigh,
  title =        {{Rayleigh-Gauss-Newton optimization with enhanced sampling for
                  variational Monte Carlo}},
  author =       {Webber, Robert J and Lindsey, Michael},
  journal =      {Physical Review Research},
  volume =       4,
  number =       3,
  pages =        033099,
  year =         2022,
  publisher =    {APS}
}

@article{kunstner2019limitations,
  title =        {{Limitations of the empirical Fisher approximation for natural
                  gradient descent}},
  author =       {Kunstner, Frederik and Hennig, Philipp and Balles, Lukas},
  journal =      {Advances in neural information processing systems},
  volume =       32,
  year =         2019
}

@article{heskes2000natural,
  title =        {On “natural” learning and pruning in multilayered perceptrons},
  author =       {Heskes, Tom},
  journal =      {Neural Computation},
  volume =       12,
  number =       4,
  pages =        {881--901},
  year =         2000,
  publisher =    {MIT Press}
}

@article{yu2018deep,
  title =        {The deep Ritz method: a deep learning-based numerical
                  algorithm for solving variational problems},
  author =       {E, Weinan and Yu, Bing},
  journal =      {Communications in Mathematics and Statistics},
  volume =       6,
  number =       1,
  pages =        {1--12},
  year =         2018,
  publisher =    {Springer}
}

@article{pearlmutter1994fast,
  author =       {Pearlmutter, Barak A.},
  title =        {{Fast Exact Multiplication by the {H}essian}},
  journal =      {Neural Computation},
  year =         1994,
  tags =         {hessian},
}

@article{schraudolph2002fast,
  title =        {Fast curvature matrix-vector products for second-order
                  gradient descent},
  author =       {Schraudolph, Nicol N},
  journal =      {Neural Computation},
  year =         2002,
}

@inproceedings{martens2010deep,
  author =       {Martens, James},
  year =         2010,
  title =        {Deep learning via {H}essian-free optimization},
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@inproceedings{tatzel2022late,
  title =        {{Late-Phase Second-Order Training}},
  author =       {Tatzel, Lukas and Hennig, Philipp and Schneider, Frank},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS),
                  Workshop Has it Trained Yet?},
  year =         2022
}

@incollection{paszke2019pytorch,
  title =        {{{PyTorch}: An Imperative Style, High-Performance Deep
                  Learning Library}},
  author =       {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{muller2024optimization,
  title =        {{Optimization in SciML--A Function Space Perspective}},
  author =       {M{\"u}ller, Johannes and Zeinhofer, Marius},
  journal =      {arXiv preprint arXiv:2402.07318},
  year =         2024
}

@article{jnini2024gauss,
  title =        {{Gauss-Newton Natural Gradient Descent for Physics-Informed
                  Computational Fluid Dynamics}},
  author =       {Jnini, Anas and Vella, Flavio and Zeinhofer, Marius},
  journal =      {arXiv preprint arXiv:2402.10680},
  year =         2024
}

@article{pfau2020ab,
  title =        {Ab initio solution of the many-electron {S}chr{\"o}dinger
                  equation with deep neural networks},
  author =       {Pfau, David and Spencer, James S and Matthews, Alexander GDG
                  and Foulkes, W Matthew C},
  journal =      {Physical Review Research},
  volume =       2,
  number =       3,
  pages =        033429,
  year =         2020,
  publisher =    {APS}
}

@article{drissi2024second,
  title =        {Second-order optimisation strategies for neural network
                  quantum states},
  author =       {Drissi, M and Keeble, JWT and Sarmiento, J Rozal{\'e}n and
                  Rios, A},
  journal =      {arXiv preprint arXiv:2401.17550},
  year =         2024
}

@article{krishnapriyan2021characterizing,
  title =        {Characterizing possible failure modes in physics-informed
                  neural networks},
  author =       {Krishnapriyan, Aditi and Gholami, Amir and Zhe, Shandian and
                  Kirby, Robert and Mahoney, Michael W},
  journal =      {Advances in Neural Information Processing Systems},
  volume =       34,
  pages =        {26548--26560},
  year =         2021
}

@article{bonfanti2024challenges,
  title =        {{The Challenges of the Nonlinear Regime for Physics-Informed
                  Neural Networks}},
  author =       {Bonfanti, Andrea and Bruno, Giuseppe and Cipriani, Cristina},
  journal =      {arXiv preprint arXiv:2402.03864},
  year =         2024
}

@article{grosse2023studying,
  title =        {Studying large language model generalization with influence
                  functions},
  author =       {Grosse, Roger and Bae, Juhan and Anil, Cem and Elhage, Nelson
                  and Tamkin, Alex and Tajdini, Amirhossein and Steiner, Benoit
                  and Li, Dustin and Durmus, Esin and Perez, Ethan and others},
  journal =      {arXiv preprint arXiv:2308.03296},
  year =         2023
}

@article{zhang2019algorithmic,
  title =        {Which algorithmic choices matter at which batch sizes?
                  insights from a noisy quadratic model},
  author =       {Zhang, Guodong and Li, Lala and Nado, Zachary and Martens,
                  James and Sachdeva, Sushant and Dahl, George and Shallue,
                  Chris and Grosse, Roger B},
  journal =      {Advances in neural information processing systems},
  volume =       32,
  year =         2019
}

@article{osawa2023pipefisher,
  title =        {Pipefisher: Efficient training of large language models using
                  pipelining and {F}isher information matrices},
  author =       {Osawa, Kazuki and Li, Shigang and Hoefler, Torsten},
  journal =      {Proceedings of Machine Learning and Systems},
  volume =       5,
  year =         2023
}

@inproceedings{pauloski2021kaisa,
  title =        {Kaisa: an adaptive second-order optimizer framework for deep
                  neural networks},
  author =       {Pauloski, J Gregory and Huang, Qi and Huang, Lei and
                  Venkataraman, Shivaram and Chard, Kyle and Foster, Ian and
                  Zhang, Zhao},
  booktitle =    {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and Analysis},
  pages =        {1--14},
  year =         2021
}

@article{chen2024teng,
  title =        {{TENG: Time-Evolving Natural Gradient for Solving PDEs with
                  Deep Neural Net}},
  author =       {Chen, Zhuo and McCarran, Jacob and Vizcaino, Esteban and
                  Solja{\v{c}}i{\'c}, Marin and Luo, Di},
  journal =      {arXiv preprint arXiv:2404.10771},
  year =         2024
}

@article{zampini2024petscml,
  title =        {{PETScML: Second-order solvers for training regression
                  problems in Scientific Machine Learning}},
  author =       {Zampini, Stefano and Zerbinati, Umberto and Turkiyyah, George
                  and Keyes, David},
  journal =      {arXiv preprint arXiv:2403.12188},
  year =         2024
}

@misc{wandb,
  title =        {{Experiment Tracking with Weights and Biases}},
  year =         2020,
  note =         {Software available from wandb.ai},
  url =          {https://www.wandb.ai/},
  author =       {Weights and Biases},
}

@article{cuomo2022scientific,
  title =        {Scientific machine learning through physics--informed neural
                  networks: Where we are and what’s next},
  author =       {Cuomo, Salvatore and Di Cola, Vincenzo Schiano and Giampaolo,
                  Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli,
                  Francesco},
  journal =      {Journal of Scientific Computing},
  volume =       92,
  number =       3,
  pages =        88,
  year =         2022,
  publisher =    {Springer}
}

@article{bruna2024neural,
  title =        {Neural Galerkin schemes with active learning for
                  high-dimensional evolution equations},
  author =       {Bruna, Joan and Peherstorfer, Benjamin and Vanden-Eijnden,
                  Eric},
  journal =      {Journal of Computational Physics},
  volume =       496,
  pages =        112588,
  year =         2024,
  publisher =    {Elsevier}
}

@article{bottou2016machine,
  author =       {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
  title =        {Optimization Methods for Large-Scale Machine Learning},
  volume =       60,
  journal =      {SIAM Review (SIREV)},
  year =         2016,
}

@inproceedings{li2024dof,
  title =        {{DOF}: Accelerating High-order Differential Operators with
                  Forward Propagation},
  author =       {Ruichen Li and Chuwei Wang and Haotian Ye and Di He and Liwei
                  Wang},
  booktitle =    {International Conference on Learning Representations (ICLR),
                  Workshop on AI4DifferentialEquations In Science},
  year =         2024,
}

@article{dangel2022vivit,
  title =        {Vi{V}i{T}: Curvature Access Through The Generalized
                  Gauss-Newton{\textquoteright}s Low-Rank Structure},
  author =       {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  journal =      {Transactions on Machine Learning Research (TMLR)},
  year =         2022,
}

@inproceedings{papyan2019measurements,
  author =       {Vardan Papyan},
  title =        {Measurements of Three-Level Hierarchical Structure in the
                  Outliers in the Spectrum of Deepnet {H}essians},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@article{clarke2023adam,
  title =        {Adam through a Second-Order Lens},
  author =       {Clarke, Ross M and Su, Baiyu and Hern{\'a}ndez-Lobato,
                  Jos{\'e} Miguel},
  year =         2023
}

@InProceedings{botev2017practical,
  title =        {Practical {G}auss-{N}ewton Optimisation for Deep Learning},
  author =       {Aleksandar Botev and Hippolyt Ritter and David Barber},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2017,
}

@article{micikevicius2017mixed,
  title =        {Mixed precision training},
  author =       {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and
                  Diamos, Gregory and Elsen, Erich and Garcia, David and
                  Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and
                  Venkatesh, Ganesh and others},
  year =         2017
}

@article{johnson2021taylor-made,
  title =        {Taylor-made higher-order automatic differentiation},
  author =       {Johnson, Matthew J and Bettencourt, Jesse and Maclaurin,
                  Dougal and Duvenaud, David},
  year =         2021,
  url =          {https://github.com/google/jax/files/6717197/jet.pdf},
  note =         {Accessed January 03, 2024}
}
